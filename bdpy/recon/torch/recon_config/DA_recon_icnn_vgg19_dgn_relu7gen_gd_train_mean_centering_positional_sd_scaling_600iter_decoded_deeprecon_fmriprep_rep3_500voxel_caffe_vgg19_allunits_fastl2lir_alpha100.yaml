general_settings:
  device: 'cuda:0'
  # label_upperbound: n01443537_22563

output_settings:
  # output_root: ./results/ImageNetTest/derivatives/reconstruction/icnn/vgg19_dgn_relu7gen_gd_train_mean_centering_positional_sd_scaling_600iter_pytorch
  output_root: /home/eitoikuta/_import_test/image_recon_test_results
  save_snapshot: True
  save_loss_hist: True
  snapshot_ext: .tiff
  retult_image_ext: .tiff
  # snapshot_interval: 1
  snapshot_interval: 200
  info_display_interval: 1 # FIXME: currently not working
  save_generator_feature: False
  save_final_encoder_activations: False # FIXME: NYI
  image_postprocess:
    mean: [104, 117, 123]
    std: [1, 1, 1]
  snapshot_postprocess: null
  no_postproc_for_snapshot: True # FIXME: currently not working

# ------------------------- #
optimization_settings:
  n_iter: 600
  image_shape: [224, 224, 3] # used only if a generator is not used

  generator:
    use_generator: True
    network_name: AlexNetGenerator_ILSVRC2012_Training_relu7
    params_file: /home/kiss/data/models_shared/pytorch/bvlc_reference_caffenet/generators/ILSVRC2012_Training/relu7/generator.pt
    feature_shape: [4096]
    output_BGR: True # this information will be used for loss settings
    output_range_255: False
    deprocess:
      output_range_255: True
      mean: [104, 117, 123]
      std: [1, 1, 1]

  normalize_gradients: True

  optimizer_info:
    # optimizer_name: Adam
    optimizer_name: SGD
    param_dicts:
      - param_name: lr
        param_values: [2., 1e-10]
      # - param_name: momentum
      #   param_values: [0.9, 0.9]

  inter_step_processes:
    - process_name: L2_decay
      param_values: [0.2, 1e-10]
    # - process_name: image_blurring
    #   param_values: [2., .5]

    - process_name: feature_clipping
      param_values:
        - null # lower bound
        - /home/kiss/data/models_shared/caffe/bvlc_reference_caffenet/generators/ILSVRC2012_Training/relu7/act_range/3x/fc7.txt # upper bound

  stabilizing_processes:
    - process_name: jittering
      jitter_size: 4

# ------------------------- #
loss_settings:
  - loss_type: ImageEncoderActivationLoss
    encoder_info:
      network_name: vgg19
      params_file: /home/kiss/data/models_shared/pytorch/VGG_ILSVRC_19_layers/VGG_ILSVRC_19_layers.pt
      model_inputs_are_RGB: False
      preprocess_from_PIL: False # TODO: where should this arg be placed?
      input_image_shape: [224, 224]
      preprocess_info:
        preprocess_input_range_255: True
        mean: [104, 117, 123]
        std: [1, 1, 1]
    image_augmentation:
      perform_augmentation: True
      n_cutouts: 10
      image_aug_dicts:
        - type: ColorJitter
          # params:
          #   brightness: [0, 0.5]
        - type: RandomAffine
        - type: RandomResizedCrop
        - type: RandomErasing
    ref_feature_info:
      input_type: image
      decoded: True # for enabling to use true features easily
      features_dir: /home/nu/data/contents_shared/ImageNetTest/derivatives/decoded_features/deeprecon_fmriprep_rep3_500voxel_allunits_fastl2lir_alpha100/decoded_features/caffe/VGG_ILSVRC_19_layers
      subjects: [SA]
      # subjects: [TH]
      rois: [VC]
      normalize_feature: True
      module_saving_names: ['conv1_1', 'conv1_2', 'conv2_1', 'conv2_2',
                            'conv3_1', 'conv3_2', 'conv3_3', 'conv3_4',
                            'conv4_1', 'conv4_2', 'conv4_3', 'conv4_4',
                            'conv5_1', 'conv5_2', 'conv5_3', 'conv5_4',
                            'fc6', 'fc7', 'fc8']

      normalization_settings:
        subtracthend:
          values: '/home/eitoikuta/reconstruction_revised/encoder_features_std/caffe/VGG_ILSVRC_19_layers/ImageNetTraining/unit-wise_mean_and_std/ImageNetTraining_unit-wise_mean.smat'
          calculation_type: 'unit-wise'
        dividor:
          values: 'std'
          calculation_type: 'positional'
          std_ddof: 0 # TODO: use the same value as multiplier
        multiplier:
          values: '/home/eitoikuta/reconstruction_revised/encoder_features_std/caffe/VGG_ILSVRC_19_layers/ImageNetBase10000/position-wise_mean_and_std/ImageNetBase10000_position-wise_std.smat'
          calculation_type: 'positional'
          std_ddof: 0 # TODO: check whether this is true
        addend:
          values: '/home/eitoikuta/reconstruction_revised/encoder_features_std/caffe/VGG_ILSVRC_19_layers/ImageNetBase10000/position-wise_mean_and_std/ImageNetBase10000_position-wise_mean.smat'
          calculation_type: 'positional'
        # addend:
        #   - values: '/home/eitoikuta/reconstruction_revised/CLIP/encoder_features_std/CLIP_ViT-B_32/ImageNetTraining/positional_mean_and_std/ImageNetTraining_positional_mean.mat'
        #     calculation_type: 'positional'
        #     target_layers: ['conv1']
        #   - values: '/home/eitoikuta/reconstruction_revised/CLIP/encoder_features_std/CLIP_ViT-B_32/ImageNetTraining/all_units_to_one_mean_and_std/ImageNetTraining_whole_mean.mat'
        #     calculation_type: 'all_units_to_one'
        #     target_layers: [...]
        # addend: null

    uniform_layer_weight: False
    loss_dicts:
      - loss_name: MSE
        weight: 1
        params:
          reduction: sum
      # - loss_name: MSEwithReguralization
      #   weight: 2
      #   params:
      #     vid: 1
      #     l_lambda: 0.01
      # - loss_name: Corr
      #   weight: 0.2
      # - loss_name: FeatCorrLoss
      #   weight: 0.6
    weight: 1

  # - loss_type: CLIPLoss
  #   encoder_info:
  #     network_name: CLIP_ViT-B_32
  #     text_input_shape: [77, 1, 512]
  #   image_augmentation:
  #     perform_augmentation: True
  #     n_cutouts: 10
  #     image_aug_dicts:
  #       - type: ColorJitter
  #         # params:
  #         #   brightness: [0, 0.5]
  #       - type: RandomAffine
  #       - type: RandomResizedCrop
  #       - type: RandomErasing
  #   ref_feature_info:
  #     input_type: text
  #     features_dir: /home/eitoikuta/reconstruction_revised/emotion/decoded_emotion_features/TH_CLIP_27-categories_fmriprep_whole-VC_500_alpha-100/decoded_features
  #     # text_feature_dir_root: /home/eitoikuta/reconstruction_revised/emotion/decoded_emotion_features
  #     # selection_type: ''
  #     # caption_type_name: ''
  #     # text_decoding_config_name: TH_CLIP_27-categories_fmriprep_whole-VC_500_alpha-100
  #     text_features_module_saving_names:
  #       - output_layer
  #     text_features_hooked_module_names:
  #       - output_layer
  #     text_features_yaml_file: /home/eitoikuta/reconstruction_revised/CLIP/recon_config/recon_with_text_config/emotion/null.yaml
  #     decoded: True
  #     subjects: [TH]
  #     rois: [whole_VC]
  #   weight: 1.4286

# normalization_settings:
#         {subtracthend: {'values': <ndarray>, 'calculation_type': 'unit-wise'},
#          divisor: {'values': <ndarray>, 'calculation_type': 'all_units_to_one', 'std_ddof': 1},
#          multiplier: {'values': <ndarray>, 'calculation_type': 'positional', 'std_ddof': 0},
#          addend: {'values': <ndarray>, 'calculation_type': 'unit-wise'}}

#         - If values is str (choices are ['std', 'mean']), values calculated from original given features will be used
#         {subtracthend: {'values': 'mean', 'calculation_type': 'unit-wise'},
#          divisor: {'values': <ndarray>, 'calculation_type': 'all_units_to_one', 'std_ddof': 1},
#          multiplier: {'values': 'std', 'calculation_type': 'positional', 'std_ddof': 1},
#          addend: {'values': <ndarray>, 'calculation_type': 'unit-wise'}}

#         - None is acceptable for all elements
#         {subtracthend: None,
#          divisor: {'values': <ndarray>, 'calculation_type': 'all_units_to_one', 'std_ddof': 1},
#          multiplier: None,
#          addend: {'values': <ndarray>, 'calculation_type': 'unit-wise'}}

#         - If 'target_layers' in the sub-dict, they will applied to only layers in the list.
#         {subtracthend: {'values': <ndarray>, 'calculation_type': 'unit-wise', 'target_layers': <list of layers>},
#          divisor: {'values': <ndarray>, 'calculation_type': 'all_units_to_one', 'std_ddof': 1},
#          multiplier: {'values': <ndarray>, 'calculation_type': 'positional', 'std_ddof': 0},
#          addend: {'values': <ndarray>, 'calculation_type': 'unit-wise'}}

#         - If you want to use different values for some layers, use following:
#         {subtracthend: [{'values': <ndarray>, 'target_layers': <list of layers>, 'calculation_type': 'unit-wise'},
#                         {'values': <ndarray>, 'target_layers': <list of layers>, 'calculation_type': 'positional'}],
#          divisor: None
#          multiplier: None
#          addend: None}